{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 金融异常检测任务"]},{"cell_type":"markdown","metadata":{},"source":["## 1. 实验介绍\n","\n","反欺诈是金融行业永恒的主题，在互联网金融信贷业务中，数字金融反欺诈技术已经得到广泛应用并取得良好效果，这其中包括了近几年迅速发展并在各个领域\n","得到越来越广泛应用的神经网络。本项目以互联网智能风控为背景，从用户相互关联和影响的视角，探索满足风控反欺诈领域需求的，可拓展、高效的神经\n","网络应用方案，从而帮助更好地识别欺诈用户。\n","\n","本项目主要关于实现预测模型(**项目用图神经网络举例，具体实现可以使用其他模型**)，进行节点异常检测任务，并验证模型精度。而本项目基于的数据集[DGraph](https://dgraph.xinye.com/introduction)，[DGraph](https://dgraph.xinye.com/introduction)\n","是大规模动态图数据集的集合，由真实金融场景中随着时间演变事件和标签构成。\n","\n","### 1.1 实验目的\n","\n","- 了解如何使用Pytorch进行神经网络训练\n","- 了解如何使用Pytorch-geometric等图网络深度学习库进行简单图神经网络设计(推荐使用GAT, GraphSAGE模型)。\n","- 了解如何利用MO平台进行模型性能评估。\n","\n","### 1.2 预备知识\n","- 具备一定的深度学习理论知识，如卷积神经网络、损失函数、优化器，训练策略等。\n","- 了解并熟悉Pytorch计算框架。\n","- 学习Pytorch-geometric，请前往：https://pytorch-geometric.readthedocs.io/en/latest/\n","    \n","### 1.3实验环境\n","- numpy = 1.26.4  \n","- pytorch = 2.3.1  \n","- torch_geometric = 2.5.3  \n","- torch_scatter = 2.1.2  \n","- torch_sparse = 0.6.18  "]},{"cell_type":"markdown","metadata":{},"source":["## 2. 实验内容"]},{"cell_type":"markdown","metadata":{},"source":["### 2.1 数据集信息\n","DGraph-Fin 是一个由数百万个节点和边组成的有向无边权的动态图。它代表了Finvolution Group用户之间的社交网络，其中一个节点对应一个Finvolution 用户，从一个用户到另一个用户的边表示**该用户将另一个用户视为紧急联系人**。\n","下面是`位于dataset/DGraphFin目录`的DGraphFin数据集的描述:\n","```\n","x:  20维节点特征向量\n","y:  节点对应标签，一共包含四类。其中类1代表欺诈用户而类0代表正常用户(实验中需要进行预测的两类标签)，类2和类3则是背景用户，即无需预测其标签。\n","edge_index:  图数据边集,每条边的形式(id_a,id_b)，其中ids是x中的索引\n","edge_type: 共11种类型的边\n","edge_timestamp: 脱敏后的时间戳\n","train_mask, valid_mask, test_mask: 训练集，验证集和测试集掩码\n","```\n","本预测任务为识别欺诈用户的节点预测任务,只需要将欺诈用户（Class 1）从正常用户（Class 0）中区分出来。需要注意的是，其中测试集中样本对应的label**均被标记为-100**。"]},{"cell_type":"markdown","metadata":{"toc-hr-collapsed":false},"source":["### 2.2 导入相关包\n","\n","导入相应模块，设置数据集路径、设备等。"]},{"cell_type":"code","execution_count":1,"id":"6d51c3ab","metadata":{},"outputs":[],"source":["from utils import DGraphFin\n","from utils.utils import prepare_folder\n","from utils.evaluator import Evaluator\n","\n","import torch\n","import torch.nn.functional as F\n","import torch.nn as nn\n","\n","import torch_geometric.transforms as T\n","\n","import numpy as np\n","from torch_geometric.data import Data\n","import os\n","\n","#设置gpu设备\n","device = 0\n","device = f'cuda:{device}' if torch.cuda.is_available() else 'cpu'\n","device = torch.device(device)\n"]},{"cell_type":"markdown","id":"176e031d","metadata":{},"source":["### 2.3 数据处理\n","\n","在使用数据集训练网络前，首先需要对数据进行归一化等预处理，如下："]},{"cell_type":"code","execution_count":2,"id":"0c0ccfb2","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([857899])\n","torch.Size([183862])\n","torch.Size([183840])\n","torch.Size([2, 7994520])\n","Data(x=[3700550, 20], edge_index=[2, 7994520], y=[3700550])\n","2\n"]}],"source":["path='./datasets/632d74d4e2843a53167ee9a1-momodel/' #数据保存路径\n","save_dir='./results/' #模型保存路径\n","dataset_name='DGraph'\n","dataset = DGraphFin(root=path, name=dataset_name, transform=T.ToSparseTensor())\n","\n","nlabels = dataset.num_classes\n","if dataset_name in ['DGraph']:\n","    nlabels = 2    #本实验中仅需预测类0和类1\n","\n","data = dataset[0]\n","data.adj_t = data.adj_t.to_symmetric() #将有向图转化为无向图\n","\n","\n","if dataset_name in ['DGraph']:\n","    x = data.x\n","    x = (x - x.mean(0)) / x.std(0)\n","    data.x = x\n","if data.y.dim() == 2:\n","    data.y = data.y.squeeze(1)\n","\n","split_idx = {'train': data.train_mask, 'valid': data.valid_mask, 'test': data.test_mask}  #划分训练集，验证集\n","print(split_idx['train'].shape)\n","print(split_idx['valid'].shape)\n","print(split_idx['test'].shape)\n","\n","train_idx = split_idx['train']\n","result_dir = prepare_folder(dataset_name,'mlp')\n","# convert data.adj_t(adjacent matrix type=SparseTensor) to edge_index shape=(2, |E|) \n","# as input for SAGEConv operator\n","edge_index = torch.stack([data.adj_t.storage.row(), data.adj_t.storage.col()], dim=0)\n","data[\"edge_index\"] = edge_index\n","print(edge_index.shape)\n","data = Data(x=data.x, edge_index=data.edge_index, y=data.y)\n","print(data)\n","print(nlabels)"]},{"cell_type":"code","execution_count":3,"id":"790245bc","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/zbw/miniconda3/envs/zju-ai-course/lib/python3.9/site-packages/torch_geometric/sampler/neighbor_sampler.py:61: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n","  warnings.warn(f\"Using '{self.__class__.__name__}' without a \"\n"]},{"name":"stdout","output_type":"stream","text":["Data(x=[1751951, 20], edge_index=[2, 1481532], y=[1751951], n_id=[1751951], e_id=[1481532], input_id=[857899], batch_size=857899)\n","Data(x=[469344, 20], edge_index=[2, 317603], y=[469344], n_id=[469344], e_id=[317603], input_id=[183840], batch_size=183840)\n","Data(x=[469481, 20], edge_index=[2, 317762], y=[469481], n_id=[469481], e_id=[317762], input_id=[183862], batch_size=183862)\n"]}],"source":["from torch_geometric.loader import NeighborLoader\n","\n","# process train/test/valid split of nodes and edges\n","train_loader = NeighborLoader(\n","    data,\n","    num_neighbors=[2],\n","    input_nodes=split_idx['train'],\n","    batch_size=len(split_idx['train']), # TODO: smaller batch_size\n","    shuffle=True\n",")\n","test_loader = NeighborLoader(\n","    data,\n","    num_neighbors=[2],\n","    input_nodes=split_idx['test'],\n","    batch_size=len(split_idx['test']), # TODO\n","    shuffle=True\n",")\n","valid_loader = NeighborLoader(\n","    data,\n","    num_neighbors=[2],\n","    input_nodes=split_idx['valid'],\n","    batch_size=len(split_idx['valid']), # TODO\n","    shuffle=True\n",")\n","for batch in train_loader:\n","    print(batch)\n","    break\n","for batch in test_loader:\n","    print(batch)\n","    break\n","for batch in valid_loader:\n","    print(batch)\n","    break"]},{"cell_type":"markdown","id":"8b587584","metadata":{},"source":["这里我们可以查看数据各部分维度"]},{"cell_type":"code","execution_count":4,"id":"baaff511","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Data(x=[3700550, 20], edge_index=[2, 7994520], y=[3700550])\n","torch.Size([3700550, 20])\n","torch.Size([3700550])\n"]}],"source":["print(data)\n","print(data.x.shape)  #feature\n","print(data.y.shape)  #label"]},{"cell_type":"markdown","metadata":{},"source":["### 2.4 定义模型"]},{"cell_type":"markdown","id":"2b1a2ef9","metadata":{},"source":["使用GNN模型，同时考虑节点和信息及其边信息作为模型输入"]},{"cell_type":"code","execution_count":5,"id":"cede25e5","metadata":{},"outputs":[],"source":["from torch_geometric.nn import SAGEConv\n","\n","class GraphSAGE(torch.nn.Module):\n","    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout):\n","        super(GraphSAGE, self).__init__()\n","        \n","        self.convs = torch.nn.ModuleList()\n","        # 第一层\n","        self.convs.append(SAGEConv(in_channels, hidden_channels))\n","        # 中间层\n","        for _ in range(num_layers - 2):\n","            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n","        # 输出层\n","        self.convs.append(SAGEConv(hidden_channels, out_channels))\n","        \n","        self.dropout = dropout\n","\n","    def reset_parameters(self):\n","        for conv in self.convs:\n","            conv.reset_parameters()\n","\n","    def forward(self, x, adj_t):\n","        for i, conv in enumerate(self.convs[:-1]):\n","            x = conv(x, adj_t)\n","            x = F.relu(x)\n","            x = F.dropout(x, p=self.dropout, training=self.training)\n","        x = self.convs[-1](x, adj_t)\n","        return F.log_softmax(x, dim=-1)"]},{"cell_type":"markdown","id":"2d3484f6","metadata":{},"source":["配置后续训练、验证、推理用到的参数。可以调整以下超参以提高模型训练后的验证精度：\n","\n","- `epochs`：在训练集上训练的代数；\n","- `lr`：学习率；\n","- `num_layers`：网络的层数；\n","- `hidden_channels`：隐藏层维数；\n","- `dropout`：dropout比例；\n","- `weight_decay`：正则化项的系数。"]},{"cell_type":"code","execution_count":6,"id":"017c0756","metadata":{},"outputs":[],"source":["# 模型参数配置\n","sage_parameters = {\n","    'lr': 0.01,\n","    'num_layers': 3,\n","    'hidden_channels': 64,\n","    'dropout': 0.5,\n","    'weight_decay': 1e-5\n","}\n","epochs = 500\n","log_steps =10 # log记录周期\n"]},{"cell_type":"code","execution_count":7,"id":"b4d9fff2","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model GraphSAGE initialized\n"]}],"source":["# 初始化模型\n","para_dict = sage_parameters\n","model_para = sage_parameters.copy()\n","model_para.pop('lr')\n","model_para.pop('weight_decay')\n","model = GraphSAGE(\n","    in_channels=data.x.size(-1),\n","    hidden_channels=sage_parameters['hidden_channels'],\n","    out_channels=nlabels,\n","    num_layers=sage_parameters['num_layers'],\n","    dropout=sage_parameters['dropout']\n",").to(device)\n","print(f'Model GraphSAGE initialized')\n","\n","eval_metric = 'auc'  #使用AUC衡量指标\n","evaluator = Evaluator(eval_metric)"]},{"cell_type":"markdown","id":"539584b9","metadata":{},"source":["初始化模型，并使用**Area Under the Curve (AUC)** 作为模型评价指标来衡量模型的表现。AUC通过对ROC曲线下各部分的面积求和而得。\n","\n","具体计算过程参见 https://github.com/scikit-learn/scikit-learn/blob/baf828ca1/sklearn/metrics/_ranking.py#L363"]},{"cell_type":"markdown","id":"c0d439d4","metadata":{},"source":["### 2.5 训练\n","\n","使用训练集中的节点用于训练模型，并使用验证集进行挑选模型。"]},{"cell_type":"code","execution_count":8,"id":"049d4401","metadata":{},"outputs":[],"source":["def train(model, data, train_idx, optimizer):\n","     # data.y is labels of shape (N, )\n","    model.train()\n","\n","    loss_list = torch.tensor([], device=device)\n","    for i, batch in enumerate(train_loader):\n","        optimizer.zero_grad()\n","\n","        out = model(batch.x, batch.edge_index)\n","    # out = model(data.x[train_idx])\n","        # 仅预测0和1的标签，去除 label 为 2,3,-100 的样本\n","        mask = batch.y != 2\n","        mask = mask & (batch.y != 3)\n","        mask = mask & (batch.y != -100)\n","        loss = F.nll_loss(out[mask], batch.y[mask])\n","        \n","        loss.backward()\n","        loss_list = torch.cat([loss_list, loss.unsqueeze(0).detach()])\n","        optimizer.step()\n","\n","    return loss_list.mean()\n","    # return loss.item()\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def test(model, data, split_idx, evaluator):\n","    # data.y is labels of shape (N, )\n","    with torch.no_grad():\n","        model.eval()\n","\n","        losses, eval_results = dict(), dict()\n","        for key in ['train', 'valid']:\n","            if key == 'train':\n","                loader = train_loader\n","            else:\n","                loader = valid_loader\n","        #     node_id = split_idx[key]            \n","            for batch in loader:\n","                out = model(batch.x, batch.edge_index)\n","                # out = model(data.x[node_id])\n","                y_pred = out.exp()  # (N,num_classes)\n","\n","                # 仅预测0和1的标签，去除 label 为 2,3,-100 的样本\n","                mask = batch.y != 2\n","                mask = mask & (batch.y != 3)\n","                mask = mask & (batch.y != -100)\n","                losses[key] = F.nll_loss(out[mask], batch.y[mask]).item()\n","                eval_results[key] = evaluator.eval(batch.y[mask], y_pred[mask])[eval_metric]\n","\n","    return eval_results, losses, y_pred\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["11138\n","Epoch: 10, Loss: 0.1302, Train: 62.813, Valid: 54.756 \n","Epoch: 20, Loss: 0.0861, Train: 66.104, Valid: 58.757 \n","Epoch: 30, Loss: 0.0751, Train: 68.884, Valid: 61.992 \n","Epoch: 40, Loss: 0.0717, Train: 70.497, Valid: 65.556 \n","Epoch: 50, Loss: 0.0695, Train: 71.229, Valid: 66.209 \n","Epoch: 60, Loss: 0.0680, Train: 72.556, Valid: 68.847 \n","Epoch: 70, Loss: 0.0673, Train: 73.004, Valid: 69.595 \n","Epoch: 80, Loss: 0.0665, Train: 73.529, Valid: 70.738 \n","Epoch: 90, Loss: 0.0661, Train: 73.991, Valid: 71.744 \n","Epoch: 100, Loss: 0.0656, Train: 74.396, Valid: 72.539 \n","Epoch: 110, Loss: 0.0651, Train: 74.669, Valid: 73.300 \n","Epoch: 120, Loss: 0.0651, Train: 74.907, Valid: 73.523 \n","Epoch: 130, Loss: 0.0649, Train: 75.158, Valid: 73.698 \n","Epoch: 140, Loss: 0.0647, Train: 75.165, Valid: 73.871 \n","Epoch: 150, Loss: 0.0646, Train: 75.281, Valid: 74.087 \n","Epoch: 160, Loss: 0.0644, Train: 75.374, Valid: 74.113 \n","Epoch: 170, Loss: 0.0643, Train: 75.533, Valid: 74.366 \n","Epoch: 180, Loss: 0.0641, Train: 75.641, Valid: 74.309 \n","Epoch: 190, Loss: 0.0639, Train: 75.654, Valid: 74.602 \n","Epoch: 200, Loss: 0.0638, Train: 75.714, Valid: 74.512 \n","Epoch: 210, Loss: 0.0637, Train: 75.778, Valid: 74.579 \n","Epoch: 220, Loss: 0.0637, Train: 75.804, Valid: 74.531 \n","Epoch: 230, Loss: 0.0636, Train: 75.895, Valid: 74.673 \n","Epoch: 240, Loss: 0.0635, Train: 75.963, Valid: 74.775 \n","Epoch: 250, Loss: 0.0633, Train: 75.950, Valid: 74.790 \n","Epoch: 260, Loss: 0.0633, Train: 75.947, Valid: 74.611 \n","Epoch: 270, Loss: 0.0632, Train: 76.030, Valid: 74.665 \n","Epoch: 280, Loss: 0.0631, Train: 76.043, Valid: 74.792 \n","Epoch: 290, Loss: 0.0629, Train: 76.060, Valid: 74.894 \n","Epoch: 300, Loss: 0.0630, Train: 76.116, Valid: 74.739 \n","Epoch: 310, Loss: 0.0627, Train: 76.149, Valid: 74.849 \n","Epoch: 320, Loss: 0.0628, Train: 76.116, Valid: 74.929 \n","Epoch: 330, Loss: 0.0628, Train: 76.097, Valid: 74.767 \n","Epoch: 340, Loss: 0.0628, Train: 76.103, Valid: 74.934 \n","Epoch: 350, Loss: 0.0627, Train: 76.256, Valid: 75.080 \n","Epoch: 360, Loss: 0.0625, Train: 76.229, Valid: 74.797 \n","Epoch: 370, Loss: 0.0626, Train: 76.253, Valid: 74.963 \n","Epoch: 380, Loss: 0.0626, Train: 76.314, Valid: 74.950 \n","Epoch: 390, Loss: 0.0624, Train: 76.311, Valid: 74.934 \n","Epoch: 400, Loss: 0.0624, Train: 76.365, Valid: 74.937 \n","Epoch: 410, Loss: 0.0624, Train: 76.296, Valid: 75.031 \n","Epoch: 420, Loss: 0.0623, Train: 76.332, Valid: 74.917 \n","Epoch: 430, Loss: 0.0624, Train: 76.378, Valid: 74.998 \n","Epoch: 440, Loss: 0.0624, Train: 76.407, Valid: 75.094 \n","Epoch: 450, Loss: 0.0623, Train: 76.407, Valid: 75.077 \n","Epoch: 460, Loss: 0.0622, Train: 76.401, Valid: 75.080 \n","Epoch: 470, Loss: 0.0622, Train: 76.426, Valid: 75.165 \n","Epoch: 480, Loss: 0.0620, Train: 76.477, Valid: 75.208 \n","Epoch: 490, Loss: 0.0623, Train: 76.555, Valid: 74.914 \n","Epoch: 500, Loss: 0.0621, Train: 76.564, Valid: 75.288 \n"]}],"source":["print(sum(p.numel() for p in model.parameters()))  #模型总参数量\n","\n","model.reset_parameters()\n","optimizer = torch.optim.Adam(model.parameters(), lr=para_dict['lr'], weight_decay=para_dict['weight_decay'])\n","best_valid = 0\n","min_valid_loss = 1e8\n","\n","data = data.to(device)\n","\n","for epoch in range(1,epochs + 1):\n","    loss = train(model, data, train_idx, optimizer)\n","    eval_results, losses, out = test(model, data, split_idx, evaluator)\n","    train_eval, valid_eval = eval_results['train'], eval_results['valid']\n","    train_loss, valid_loss = losses['train'], losses['valid']\n","\n","    if valid_loss < min_valid_loss:\n","        min_valid_loss = valid_loss\n","        torch.save(model.state_dict(), save_dir+'/model.pt') #将表现最好的模型保存\n","\n","    if epoch % log_steps == 0:\n","        print(f'Epoch: {epoch:02d}, '\n","              f'Loss: {loss:.4f}, '\n","              f'Train: {100 * train_eval:.3f}, ' # 我们将AUC值乘上100，使其在0-100的区间内\n","              f'Valid: {100 * valid_eval:.3f} ')\n"]},{"cell_type":"markdown","metadata":{"inputHidden":false},"source":["### 2.6 模型预测"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([3700550, 2])\n"]}],"source":["model.load_state_dict(torch.load(save_dir+'/model.pt')) #载入验证集上表现最好的模型\n","node_id_result_mapping = model(data.x, data.edge_index) # 所有节点全部预测一遍，然后直接查表\n","print(node_id_result_mapping.shape)\n","\n","def predict(data,node_id):\n","    \"\"\"\n","    加载模型和模型预测\n","    :param node_id: int, 需要进行预测节点的下标\n","    :return: tensor, 类0以及类1的概率, torch.size[1,2]\n","    \"\"\"\n","    # -------------------------- 实现模型预测部分的代码 ---------------------------\n","    with torch.no_grad():\n","        model.eval()\n","        # out = model(data.x[node_id])\n","        out = node_id_result_mapping[node_id]\n","        y_pred = out.exp()  # (N,num_classes)\n","\n","    return y_pred\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([0.9841, 0.0159])\n","节点 0 预测对应的标签为:0, 为正常用户。\n","tensor([0.9862, 0.0138])\n","节点 1 预测对应的标签为:0, 为正常用户。\n"]}],"source":["dic={0:\"正常用户\",1:\"欺诈用户\"}\n","node_idx = 0\n","y_pred = predict(data, node_idx)\n","print(y_pred)\n","print(f'节点 {node_idx} 预测对应的标签为:{torch.argmax(y_pred)}, 为{dic[torch.argmax(y_pred).item()]}。')\n","\n","node_idx = 1\n","y_pred = predict(data, node_idx)\n","print(y_pred)\n","print(f'节点 {node_idx} 预测对应的标签为:{torch.argmax(y_pred)}, 为{dic[torch.argmax(y_pred).item()]}。')\n"]},{"cell_type":"markdown","id":"848d712a","metadata":{},"source":["保存所有节点的预测结果，快速答案评测"]},{"cell_type":"code","execution_count":13,"id":"f9f2f70b","metadata":{},"outputs":[],"source":["import pickle\n","model.load_state_dict(torch.load(save_dir+'/model.pt')) #载入验证集上表现最好的模型\n","node_id_result_mapping = model(data.x, data.edge_index).to('cpu')\n","pickle.dump(node_id_result_mapping, open('node_id_result_mapping.pkl', 'wb'))"]},{"cell_type":"markdown","metadata":{},"source":["## 3. 作业评分\n","\n","**作业要求**：    \n","                         \n","1. 请加载你认为训练最佳的模型（不限于图神经网络)\n","2. 提交的作业包括【程序报告.pdf】和代码文件。\n","\n","**注意：**\n","          \n","1. 在训练模型等过程中如果需要**保存数据、模型**等请写到 **results** 文件夹，如果采用 [离线任务](https://momodel.cn/docs/#/zh-cn/%E5%9C%A8GPU%E6%88%96CPU%E8%B5%84%E6%BA%90%E4%B8%8A%E8%AE%AD%E7%BB%83%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B) 请务必将模型保存在 **results** 文件夹下。\n","2. 训练出自己最好的模型后，先按照下列 cell 操作方式实现 NoteBook 加载模型测试；请测试通过在进行【系统测试】。\n","3. 点击左侧栏`提交作业`后点击`生成文件`则只需勾选 `predict()` 函数的cell，即【**模型预测代码答题区域**】的 cell。\n","4. 请导入必要的包和第三方库 (包括此文件中曾经导入过的)。\n","5. 请加载你认为训练最佳的模型，即请按要求填写**模型路径**。\n","6. `predict()`函数的输入和输出请不要改动。"]},{"cell_type":"markdown","metadata":{},"source":["===========================================  **模型预测代码答题区域**  =========================================== \n","\n","在下方的代码块中编写 **模型预测** 部分的代码，请勿在别的位置作答"]},{"cell_type":"code","execution_count":2,"metadata":{"select":true},"outputs":[],"source":["## 生成 main.py 时请勾选此 cell\n","from utils import DGraphFin\n","from utils.evaluator import Evaluator\n","import torch\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import torch_geometric.transforms as T\n","from torch_geometric.data import Data\n","import numpy as np\n","import os\n","import pickle\n","\n","# model.load_state_dict(torch.load(save_dir+'/model.pt')) #载入验证集上表现最好的模型\n","# node_id_result_mapping = model(data.x)\n","\n","# lookup table\n","node_id_result_mapping = pickle.load(open('node_id_result_mapping.pkl', 'rb'))\n","\n","def predict(data,node_id):\n","    \"\"\"\n","    加载模型和模型预测\n","    :param node_id: int, 需要进行预测节点的下标\n","    :return: tensor, 类0以及类1的概率, torch.size[1,2]\n","    \"\"\"\n","    # -------------------------- 实现模型预测部分的代码 ---------------------------\n","    with torch.no_grad():\n","        model.eval()\n","        # out = model(data.x[node_id])\n","        out = node_id_result_mapping[node_id]\n","        y_pred = out.exp()  # (N,num_classes)\n","\n","    return y_pred\n"]}],"metadata":{"kernelspec":{"display_name":"zju-ai-course","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.20"}},"nbformat":4,"nbformat_minor":5}
